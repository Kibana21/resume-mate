# Resume Mate - Project Structure

## ğŸ“ Directory Structure

```
resume-mate/
â”œâ”€â”€ README.md                          # Main project documentation
â”œâ”€â”€ TECHNICAL_ARCHITECTURE_DSPY.md    # DSPy technical architecture
â”œâ”€â”€ ADVANCED_DSPY_PATTERNS.md         # Advanced patterns guide
â”œâ”€â”€ PROJECT_STRUCTURE.md              # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ pyproject.toml                    # Poetry configuration
â”œâ”€â”€ .env.example                      # Environment variables template
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”‚
â”œâ”€â”€ src/                              # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/                       # Configuration management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py              # Application settings (Pydantic)
â”‚   â”‚   â”œâ”€â”€ dspy_config.py           # DSPy initialization
â”‚   â”‚   â””â”€â”€ division_config.py       # Division-specific configs
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                       # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cv_schema.py             # CV data models
â”‚   â”‚   â”œâ”€â”€ jd_schema.py             # JD data models
â”‚   â”‚   â”œâ”€â”€ evidence_field.py        # Evidence-based extraction models
â”‚   â”‚   â”œâ”€â”€ hr_insights.py           # HR insights models
â”‚   â”‚   â”œâ”€â”€ evaluation_criteria.py   # Matching criteria models
â”‚   â”‚   â””â”€â”€ database.py              # SQLAlchemy models
â”‚   â”‚
â”‚   â”œâ”€â”€ dspy_modules/                 # DSPy signatures and modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cv_signatures.py         # CV extraction signatures
â”‚   â”‚   â”œâ”€â”€ jd_signatures.py         # JD extraction signatures
â”‚   â”‚   â”œâ”€â”€ cv_extraction_modules.py # CV extraction modules
â”‚   â”‚   â”œâ”€â”€ jd_extraction_modules.py # JD extraction modules
â”‚   â”‚   â”œâ”€â”€ evidence_extractors.py   # Evidence-based extractors
â”‚   â”‚   â”œâ”€â”€ hr_insights_signature.py # HR insights extraction
â”‚   â”‚   â””â”€â”€ matching_signatures.py   # Matching/evaluation signatures
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/                    # End-to-end pipelines
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cv_extraction_pipeline.py    # CV extraction pipeline
â”‚   â”‚   â”œâ”€â”€ jd_extraction_pipeline.py    # JD extraction pipeline
â”‚   â”‚   â”œâ”€â”€ enhanced_cv_extraction.py    # With evidence & insights
â”‚   â”‚   â”œâ”€â”€ matching_pipeline.py         # CV-JD matching
â”‚   â”‚   â””â”€â”€ division_aware_extraction.py # Division-specific extraction
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/                # Document preprocessing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_parser.py       # PDF, DOCX, image parsing
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py          # Text normalization
â”‚   â”‚   â”œâ”€â”€ ocr_processor.py         # OCR for images
â”‚   â”‚   â””â”€â”€ skill_normalizer.py      # Skill/title normalization
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                   # Evaluation & optimization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py               # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ teleprompter_optimization.py # DSPy optimization
â”‚   â”‚   â””â”€â”€ training_data_creation.py    # Training data utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                        # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py                # Logging configuration
â”‚   â”‚   â”œâ”€â”€ cache.py                 # Caching utilities
â”‚   â”‚   â”œâ”€â”€ validators.py            # Data validation
â”‚   â”‚   â””â”€â”€ helpers.py               # Helper functions
â”‚   â”‚
â”‚   â””â”€â”€ api/                          # FastAPI application
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py                  # FastAPI app entry
â”‚       â”œâ”€â”€ routes/                  # API routes
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ cv_extraction.py     # CV extraction endpoints
â”‚       â”‚   â”œâ”€â”€ jd_extraction.py     # JD extraction endpoints
â”‚       â”‚   â”œâ”€â”€ matching.py          # Matching endpoints
â”‚       â”‚   â””â”€â”€ health.py            # Health check endpoints
â”‚       â”œâ”€â”€ dependencies.py          # FastAPI dependencies
â”‚       â”œâ”€â”€ middleware.py            # API middleware
â”‚       â””â”€â”€ schemas.py               # API request/response schemas
â”‚
â”œâ”€â”€ tests/                            # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                  # Pytest configuration
â”‚   â”œâ”€â”€ unit/                        # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_cv_extraction.py
â”‚   â”‚   â”œâ”€â”€ test_jd_extraction.py
â”‚   â”‚   â”œâ”€â”€ test_matching.py
â”‚   â”‚   â””â”€â”€ test_evidence_extraction.py
â”‚   â”œâ”€â”€ integration/                 # Integration tests
â”‚   â”‚   â”œâ”€â”€ test_pipelines.py
â”‚   â”‚   â”œâ”€â”€ test_api.py
â”‚   â”‚   â””â”€â”€ test_division_aware.py
â”‚   â””â”€â”€ fixtures/                    # Test fixtures
â”‚       â”œâ”€â”€ sample_cv.txt
â”‚       â”œâ”€â”€ sample_jd.txt
â”‚       â””â”€â”€ expected_outputs.json
â”‚
â”œâ”€â”€ data/                             # Data directory
â”‚   â”œâ”€â”€ sample_cvs/                  # Sample CVs for testing
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ technology_cv_1.pdf
â”‚   â”‚   â”œâ”€â”€ insurance_cv_1.pdf
â”‚   â”‚   â””â”€â”€ legal_cv_1.pdf
â”‚   â”œâ”€â”€ sample_jds/                  # Sample JDs for testing
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ technology_jd_1.txt
â”‚   â”‚   â””â”€â”€ insurance_jd_1.txt
â”‚   â”œâ”€â”€ training_data/               # Training data for optimization
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â”œâ”€â”€ cv_training.json
â”‚   â”‚   â””â”€â”€ jd_training.json
â”‚   â””â”€â”€ uploads/                     # Runtime uploads (gitignored)
â”‚
â”œâ”€â”€ scripts/                          # Utility scripts
â”‚   â”œâ”€â”€ init_db.py                   # Initialize database
â”‚   â”œâ”€â”€ run_extraction.py            # Run extraction on samples
â”‚   â”œâ”€â”€ optimize_models.py           # Run DSPy optimization
â”‚   â”œâ”€â”€ generate_training_data.py    # Generate training examples
â”‚   â””â”€â”€ benchmark.py                 # Performance benchmarking
â”‚
â”œâ”€â”€ docs/                             # Documentation
â”‚   â”œâ”€â”€ index.md                     # Documentation home
â”‚   â”œâ”€â”€ getting_started.md           # Quick start guide
â”‚   â”œâ”€â”€ api_reference.md             # API documentation
â”‚   â”œâ”€â”€ division_guide.md            # Division-specific guide
â”‚   â””â”€â”€ deployment.md                # Deployment guide
â”‚
â”œâ”€â”€ notebooks/                        # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_cv_extraction_demo.ipynb
â”‚   â”œâ”€â”€ 02_jd_extraction_demo.ipynb
â”‚   â”œâ”€â”€ 03_matching_demo.ipynb
â”‚   â”œâ”€â”€ 04_optimization_demo.ipynb
â”‚   â””â”€â”€ 05_evaluation_demo.ipynb
â”‚
â”œâ”€â”€ logs/                             # Application logs (gitignored)
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ .github/                          # GitHub configuration
    â””â”€â”€ workflows/
        â”œâ”€â”€ tests.yml                # CI/CD tests
        â”œâ”€â”€ lint.yml                 # Linting
        â””â”€â”€ deploy.yml               # Deployment
```

## ğŸ“¦ Module Descriptions

### `src/config/`
Configuration management with environment variables, DSPy setup, and division-specific configurations.

**Key Files:**
- `settings.py`: Pydantic settings with env var support
- `dspy_config.py`: DSPy LM initialization
- `division_config.py`: Division contexts and extraction configs

### `src/models/`
Pydantic data models for type-safe data structures.

**Key Files:**
- `cv_schema.py`: CandidateProfile, WorkExperience, Education, Skill models
- `jd_schema.py`: JobDescription, SkillRequirement, ExperienceRequirement models
- `evidence_field.py`: EvidenceField, EvidenceSkill with confidence scores
- `hr_insights.py`: HRInsights, QualityScore models
- `evaluation_criteria.py`: CriterionConfig, MatchEvidence, CVJDEvaluation models

### `src/dspy_modules/`
DSPy signatures and modules for extraction.

**Key Files:**
- `cv_signatures.py`: DSPy signatures for CV extraction
- `cv_extraction_modules.py`: DSPy modules wrapping signatures
- `evidence_extractors.py`: Evidence-based extraction modules
- `hr_insights_signature.py`: HR insights extraction
- `matching_signatures.py`: CV-JD matching signatures

### `src/pipelines/`
End-to-end extraction and matching pipelines.

**Key Files:**
- `cv_extraction_pipeline.py`: Complete CV extraction pipeline
- `jd_extraction_pipeline.py`: Complete JD extraction pipeline
- `enhanced_cv_extraction.py`: With evidence, HR insights, quality scoring
- `matching_pipeline.py`: CV-JD matching with evidence
- `division_aware_extraction.py`: Division-specific extraction

### `src/preprocessing/`
Document parsing and text preprocessing.

**Key Files:**
- `document_parser.py`: Parse PDF, DOCX, images to text
- `text_cleaner.py`: Text normalization and cleaning
- `ocr_processor.py`: OCR for image-based CVs
- `skill_normalizer.py`: Normalize skills, titles, degrees

### `src/evaluation/`
Model evaluation and optimization.

**Key Files:**
- `metrics.py`: Extraction accuracy, F1, precision/recall metrics
- `teleprompter_optimization.py`: DSPy BootstrapFewShot, MIPRO optimization
- `training_data_creation.py`: Create training examples

### `src/api/`
FastAPI REST API.

**Key Files:**
- `main.py`: FastAPI app initialization
- `routes/cv_extraction.py`: POST /api/cv/extract endpoint
- `routes/jd_extraction.py`: POST /api/jd/extract endpoint
- `routes/matching.py`: POST /api/match endpoint

### `tests/`
Comprehensive test suite.

**Directories:**
- `unit/`: Unit tests for individual modules
- `integration/`: End-to-end integration tests
- `fixtures/`: Sample data and expected outputs

### `scripts/`
Utility scripts for common tasks.

**Key Scripts:**
- `run_extraction.py`: Test extraction on sample CVs/JDs
- `optimize_models.py`: Run DSPy optimization
- `generate_training_data.py`: Create training examples
- `benchmark.py`: Performance benchmarking

### `notebooks/`
Jupyter notebooks for exploration and demos.

**Notebooks:**
- `01_cv_extraction_demo.ipynb`: CV extraction walkthrough
- `02_jd_extraction_demo.ipynb`: JD extraction walkthrough
- `03_matching_demo.ipynb`: CV-JD matching demo
- `04_optimization_demo.ipynb`: DSPy optimization tutorial
- `05_evaluation_demo.ipynb`: Evaluation metrics demo

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or using poetry
poetry install

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### 2. Initialize DSPy

```bash
# Run a test extraction
python scripts/run_extraction.py data/sample_cvs/technology_cv_1.pdf
```

### 3. Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test
pytest tests/unit/test_cv_extraction.py -v
```

### 4. Start API Server

```bash
# Development mode
uvicorn src.api.main:app --reload --port 8000

# Production mode
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 5. Explore with Notebooks

```bash
jupyter notebook notebooks/
```

## ğŸ“Š Development Workflow

### Phase 1: Basic Extraction (Week 1)
1. Implement `cv_extraction_pipeline.py`
2. Test with sample CVs
3. Achieve 70%+ accuracy

### Phase 2: Evidence & Insights (Week 2)
1. Add evidence-based extraction
2. Implement HR insights
3. Add quality scoring

### Phase 3: JD & Matching (Week 3)
1. Implement JD extraction
2. Build matching pipeline
3. Add configurable criteria

### Phase 4: Optimization (Week 4)
1. Collect training data
2. Run DSPy optimization
3. Achieve 85%+ accuracy

### Phase 5: API & Integration (Week 5-6)
1. Build FastAPI endpoints
2. Add async processing
3. Deploy to production

## ğŸ”§ Configuration

### Environment Variables
See `.env.example` for all configuration options.

### Division-Specific Configs
Edit `src/config/division_config.py` to customize:
- Matching weights per division
- Quality thresholds
- Priority fields
- Strict mode settings

## ğŸ“ Coding Standards

### Code Style
- **Formatter**: Black (line length 100)
- **Import sorting**: isort
- **Linting**: Flake8, Pylint
- **Type checking**: mypy

### Run Code Quality Checks
```bash
# Format code
black src/ tests/

# Sort imports
isort src/ tests/

# Type checking
mypy src/

# Linting
flake8 src/ tests/
pylint src/
```

## ğŸ§ª Testing

### Test Coverage Goals
- Unit tests: 80%+ coverage
- Integration tests: Critical paths covered
- E2E tests: Main user flows tested

### Run Tests
```bash
# All tests
pytest

# Specific test file
pytest tests/unit/test_cv_extraction.py

# With verbose output
pytest -v

# With coverage report
pytest --cov=src --cov-report=html
open htmlcov/index.html
```

## ğŸ“š Documentation

### Generate Docs
```bash
mkdocs build
mkdocs serve  # View at http://localhost:8000
```

## ğŸš¢ Deployment

See `docs/deployment.md` for production deployment guide.

### Quick Deploy (Docker)
```bash
docker build -t resume-mate:latest .
docker run -p 8000:8000 --env-file .env resume-mate:latest
```

## ğŸ¤ Contributing

1. Create feature branch
2. Write tests
3. Implement feature
4. Run code quality checks
5. Submit PR

## ğŸ“ Support

For questions or issues, contact the AIA Team or open an issue on GitHub.

---

**Last Updated**: 2025-01-27
**Version**: 0.1.0
