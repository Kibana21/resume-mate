# ‚úÖ Setup Complete - Ready to Extract CVs!

## üéâ Everything is Ready!

Your Resume Mate platform is now configured and ready to extract structured data from CVs using Azure OpenAI.

---

## üìç Quick Start (3 Steps)

### Step 1: Install Dependencies
```bash
pip install pydantic pydantic-settings dspy-ai openai pdfplumber python-docx loguru
```

### Step 2: Configure Azure OpenAI
Edit `.env` file:
```bash
AZURE_OPENAI_API_KEY=your_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

### Step 3: Run Extraction
```bash
# Place your resume in data/sample_cvs/resume.pdf, then:
python scripts/extract_cv.py data/sample_cvs/resume.pdf
```

---

## üìÇ Where to Put Your Resume

```
data/sample_cvs/resume.pdf  ‚Üê PUT YOUR RESUME HERE
```

Or use any path:
```bash
python scripts/extract_cv.py /path/to/your/resume.pdf
```

---

## üéØ What's Been Configured

### ‚úÖ Azure OpenAI Only
- Removed OpenAI and Anthropic dependencies
- Simplified configuration to Azure only
- Uses `dspy.LM()` with your Azure credentials

### ‚úÖ Complete Data Models
- 60+ Pydantic models for CV and JD data
- Evidence-based extraction with confidence scores
- HR insights (career progression, red flags, quality scoring)
- Evaluation framework for CV-JD matching

### ‚úÖ DSPy Extraction System
- 43 extraction signatures
- 45+ reusable modules
- End-to-end pipelines for CV and JD
- Multi-division support (all 10 AIA divisions)

### ‚úÖ PDF/DOCX Parser
- Extracts text from PDF files
- Supports DOCX and TXT files
- Auto-detects file format

### ‚úÖ Ready-to-Use Script
- `scripts/extract_cv.py` - Simple command-line tool
- Console output or JSON file
- Multiple options (evidence, industry, strict mode)

---

## üìö Documentation Available

| File | Purpose |
|------|---------|
| **[HOW_TO_RUN.md](HOW_TO_RUN.md)** | üìå **START HERE** - Quick reference |
| [QUICKSTART.md](QUICKSTART.md) | Detailed step-by-step guide |
| [AZURE_SETUP.md](AZURE_SETUP.md) | Azure OpenAI setup instructions |
| [CHANGES_SUMMARY.md](CHANGES_SUMMARY.md) | All configuration changes made |
| [IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md) | What's implemented (60% complete) |
| [TECHNICAL_ARCHITECTURE_DSPY.md](TECHNICAL_ARCHITECTURE_DSPY.md) | DSPy architecture details |
| [README.md](README.md) | Complete requirements document |

---

## üíª Example Commands

### Basic extraction:
```bash
python scripts/extract_cv.py data/sample_cvs/resume.pdf
```

### Save to JSON:
```bash
python scripts/extract_cv.py data/sample_cvs/resume.pdf --output data/outputs/result.json
```

### With industry context:
```bash
python scripts/extract_cv.py data/sample_cvs/resume.pdf --industry technology
```

### With evidence spans:
```bash
python scripts/extract_cv.py data/sample_cvs/resume.pdf --evidence
```

### Fast mode (no HR insights):
```bash
python scripts/extract_cv.py data/sample_cvs/resume.pdf --no-hr-insights
```

---

## üîç What Gets Extracted

From your `resume.pdf`, the system extracts:

‚úÖ **Personal Information**
- Name, email, phone, location
- LinkedIn, GitHub, portfolio URLs
- Professional summary

‚úÖ **Work Experience**
- Company name, job title, dates
- Responsibilities and achievements
- Technologies used

‚úÖ **Education**
- Degree, institution, field of study
- GPA, honors, relevant coursework

‚úÖ **Skills**
- Technical skills (categorized)
- Soft skills
- Domain expertise
- Proficiency levels

‚úÖ **Certifications**
- Professional certifications
- Issue and expiration dates
- Status (active/expired)

‚úÖ **Career Analysis**
- Total years of experience
- Career level (Entry/Mid/Senior/Executive)
- Division classification (which AIA division)

‚úÖ **HR Insights** (optional)
- Career progression analysis
- Job hopping detection
- Employment gaps
- Red flags and quality scoring

---

## üìä Sample Output

```json
{
  "personal_info": {
    "full_name": "John Doe",
    "email": "john.doe@email.com",
    "phone": "+1-555-0123",
    "location": "San Francisco, CA"
  },
  "work_experience": [
    {
      "company_name": "Tech Corp",
      "job_title": "Senior Software Engineer",
      "start_date": "2020-05-01",
      "is_current": true,
      "responsibilities": [...],
      "technologies_used": [...]
    }
  ],
  "skills": [
    {"name": "Python", "category": "technical"},
    {"name": "AWS", "category": "technical"},
    ...
  ],
  "total_years_experience": 8.5,
  "career_level": "Senior",
  "primary_division": "technology"
}
```

---

## üêç Python API Usage

```python
from src.config import init_dspy
from src.pipelines import CVExtractionPipeline

# Initialize DSPy with Azure OpenAI
lm = init_dspy()

# Create pipeline
pipeline = CVExtractionPipeline(
    with_evidence=True,
    with_hr_insights=True,
    industry_domain="technology"
)

# Extract from file
profile = pipeline.extract_from_file("data/sample_cvs/resume.pdf")

# Access data
print(f"Name: {profile.personal_info.full_name}")
print(f"Experience: {profile.total_years_experience} years")
print(f"Skills: {len(profile.skills)}")

# Get technical skills
tech_skills = [s.name for s in profile.skills if s.category == "technical"]
print(f"Technical: {', '.join(tech_skills)}")

# Save to JSON
import json
with open("output.json", "w") as f:
    json.dump(profile.model_dump(mode='json'), f, indent=2, default=str)
```

---

## ‚ö° Performance

- **Simple CV** (1-2 pages): ~30 seconds
- **Standard CV** (2-3 pages): ~45 seconds
- **Complex CV** (4+ pages): ~60 seconds

*First run may be slower due to model initialization*

---

## üõ†Ô∏è Troubleshooting

### Dependencies not installed?
```bash
pip install pydantic pydantic-settings dspy-ai openai pdfplumber python-docx loguru
```

### Azure credentials not set?
```bash
# Check .env file exists
ls -la .env

# View contents (hide API key)
cat .env | grep AZURE_OPENAI_ENDPOINT
```

### File not found?
```bash
# Check file exists
ls data/sample_cvs/resume.pdf

# Or use absolute path
python scripts/extract_cv.py /Users/kartik/Desktop/resume.pdf
```

### Extraction fails?
- Check Azure OpenAI quota in portal
- Verify deployment name matches exactly
- Try `--no-hr-insights` for faster/simpler extraction

---

## üöÄ Next Steps

1. **Extract Your Resume**: Try it with your own CV
2. **Batch Processing**: Process multiple CVs
3. **Job Description Matching**: Extract JD and match candidates
4. **Custom Analysis**: Modify for specific requirements
5. **API Development**: Build REST API for production

---

## üìû Support Resources

- **Azure OpenAI Docs**: https://learn.microsoft.com/en-us/azure/ai-services/openai/
- **DSPy Documentation**: https://dspy-docs.vercel.app/
- **Pydantic Docs**: https://docs.pydantic.dev/

---

## üéØ You're All Set!

Just place your `resume.pdf` in `data/sample_cvs/` and run:

```bash
python scripts/extract_cv.py data/sample_cvs/resume.pdf
```

**Happy extracting! üöÄ**
